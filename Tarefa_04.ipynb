{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarefa 04.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FFxhdO05s_P_",
        "JFEJqP7ox3v4"
      ],
      "authorship_tag": "ABX9TyP5QZ5As6iG+W7iahjGsT7b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathvbl/math/blob/main/Tarefa_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFxhdO05s_P_"
      },
      "source": [
        "# ***Funções e Bibliotecas Utilizadas***\n",
        "Aqui estão todas as funções e as bibliotecas que serão utilizadas para a resolução da tarefa e para execução do código.\n",
        "\n",
        "A função **Read()** foi utilizada para abrir arquivos. Ela abre um arquivo, copia os dados desse arquivo para a variável ArqContent, fecha o arquivo e retorna a variável ArqContent.\n",
        "\n",
        "A função **Clean()**, função adaptada [1], recebe uma lista contendo diversos caracteres, a variável **Lixo** conterá os caracteres a serem removidos, a variável **Limpando** conterá a lista recebida pela função com as letras minusculas e com os caracteres contidos na variável **Lixo**  removidos, isso será feito pela função **lower()** que deixa o caractere em minusculo e a função **strip** que retorna a cópia da lista  com os caracteres removidos, no final antes de retornar a nova lista função verificará se toda a lista esta formada apenas por caracteres com letras do alfabeto e  hífen (-).\n",
        "\n",
        "A função **Countc()** foi utilizada para contar o número de caracteres.Ela recebe uma lista de caracteres,percorre essa lista com um contador e retorna esse contador.\n",
        "\n",
        "A função **Ocurrences()** função adaptada [1], foi utilizada para verificar a ocorrência de determinada palavra em uma lista. Ela recebe um lista contendo determinado conjunto de palavras e cria um dicionario o **Dict** e  esse dicionario está representado por **defaultdict(int)** o que resultará na seguinte situação, caso a chave não estiver representada no dicionário ela será representada relacionando a chave ao valor 0,ou seja,dado uma lista de palavras a verificação de ocorrência dessa palavra será definida pela chave, sempre que a chave for igual, **Dict** será incrementado, quando uma nova chave for descoberta será atribuída ao valor 0 e será pesquisado mais dessa chave na lista, quando toda lista for percorrida a variavel **Dict** será retornado pela função."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z65eqsZMtTtA"
      },
      "source": [
        "from typing import Dict\n",
        "from collections import defaultdict\n",
        "nltk.download('all')\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def Read(FileName):\n",
        "  Arquivo = open(FileName, 'r', encoding='utf-8')\n",
        "  ArqContent = Arquivo.read()\n",
        "  Arquivo.close()\n",
        "  return ArqContent\n",
        "\n",
        "\n",
        "def Clean(lista):\n",
        "  Lixo = '.,:.;?!\"`()[]{}\\/|#$%^&*'\n",
        "  Limpando = [newlist.strip(Lixo).lower() for newlist in lista]\n",
        "  return [newlist for newlist in Limpando if newlist.isalpha() or '-' in newlist]\n",
        "\n",
        "def CountC(lista):\n",
        "  contador = 0\n",
        "  for contador in range(len(lista)):\n",
        "    pass\n",
        "  return contador\n",
        "\n",
        "def Occurrences(lista):\n",
        "    Dict = defaultdict(int)\n",
        "    for p in lista:\n",
        "       Dict[p] += 1\n",
        "    \n",
        "    return Dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JrBkdOQotG4"
      },
      "source": [
        "# ***Abrindo os Arquivos .txt***\n",
        "Como a tarefa necessitará de dois arquivos para  resolução, o código abaixo mostra a abertura dos mesmo, a variável que guardará os dados do livro Memórias Póstumas está denominada como **LivroMP**, enquanto a que guardará os dados do Livro Dom Casmurro está denominada como **LivroDC**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2G9bcvApaIq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "bfddd988-1ef1-423d-cedf-45f1ab642d0d"
      },
      "source": [
        "LivroMP = Read('MemóriasPóstumas.txt')\n",
        "LivroDC = Read('DomCasmurro.txt')"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-e17c97e23cf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://raw.githubusercontent.com/mathvbl/math/main/DomCasmurro.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mLivroMP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MemóriasPóstumas.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 3 fields in line 24, saw 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRMMnSGAweAR"
      },
      "source": [
        "#***Contando os números de caracteres***\n",
        "O código abaixo conta o número de caracteres de determinada lista, nesse caso a lista que terá seus caracteres calculados será a **LivroMP** que representa o livro 'Memórias Póstumas', a váriavel **NumeroCaracteres** guardará o valor retornado pela função **Countc()**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5zOjvmdxDme"
      },
      "source": [
        "NumeroCaracteres = CountC(LivroMP)\n",
        "\n",
        "print(\"Numero de Caracteres: \",NumeroCaracteres)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFEJqP7ox3v4"
      },
      "source": [
        "# ***Limpeza de Conjunto, palavras do texto e  riqueza lexical***\n",
        "Nessa parte a função **word_tokenize()** irá separar a string LivroMP em uma lista de tokens, essa lista será atribuída a variável **PalavrasMP** e  terá alguns caracteres removido pela função **Clean()**, caracteres como '.' e '#'.\n",
        "Para calcular a quantidade de palavras no texto, será necessário a contagem apenas de palavras não repetidas, portanto a função **set()** foi utilizada no código, ela transforma a lista **PalavrasMP** em um conjunto desordenado e sem elementos iguais, esse conjunto é atribuído a variável **QuantPalavras**, após isso o calculo da quantidade de palavras é feita pela função **len()** que retorna o tamanho da variável **QuantPalavras**.\n",
        "O cálculo de riqueza lexical foi feito dividindo a quantidade de palavras que não são duplicatas pelo numero total de palavras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJDPsKjdx6x9",
        "outputId": "e084bf8c-6561-4626-ba68-6dd4e7d19cf1"
      },
      "source": [
        "\n",
        "PalavrasMP = word_tokenize(LivroMP)\n",
        "PalavrasMP = Clean(PalavrasMP)\n",
        "QuantPalavras = set(PalavrasMP)\n",
        "RiquezaLexical = len(QuantPalavras)/len(PalavrasMP)\n",
        "\n",
        "print(\"Numero de PalavrasMP: \",len(QuantPalavras))\n",
        "print(\"Riqueza lexical: \",RiquezaLexical)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero de PalavrasMP:  10429\n",
            "Riqueza lexical:  0.1730609671102851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akwhfxsMCn2j"
      },
      "source": [
        "# ***Representação textual das palavras semelhantes entre as mais frequentes dos arquivos***\n",
        "\n",
        "Aqui é a representação das palavras que estão entre as vinte mais frequentes nos dois arquivos. Primeiramente é feita a tokenização e a limpeza do texto Dom Casmurro , da mesma forma que foi feita para o texto Memórias Póstumas, depois é definido o total de ocorrências das palavras dos dois textos pela função **Occurrences()** a qual retorna um valor que é guardado nas variáveis  **DictMP** e **DictDC** que representam as ocorrências dos textos Memórias Póstumas e Dom Casmurro respectivamente.\n",
        "A função **sorted()** é utilizada para ordenar os 20 maiores valores das variáveis **DictMP** e **DictDC**,ou seja, ele organizará as 20 palavras com mais ocorrência em ambos os textos.\n",
        "O primeiro **for** é para o conjunto de palavras do texto Memórias Póstumas e o segundo **for** para o de Dom Casmurro, no segundo **for** será feita uma comparação da palavra do texto Memórias Póstumas com todas as palavras do texto Dom Casmurro,se alguma delas forem iguais sua informações serão guardadas na variável **PalavrasSemelhantes**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhrooUNpCuo7"
      },
      "source": [
        "DictMP = Occurrences(PalavrasMP)\n",
        "PalFrequentesMP = sorted(DictMP.items(), key=lambda tupla:tupla[1], reverse=True)[:20]\n",
        "\n",
        "PalavrasDC = word_tokenize(LivroDM)\n",
        "PalavrasDC = Clean(PalavrasDC)\n",
        "DictDC = Occurrences(PalavrasDC)\n",
        "PalFrequentesDC = sorted(DictDC.items(), key=lambda tupla:tupla[1], reverse=True)[:20]\n",
        "\n",
        "PalavrasSemelhantes = ''\n",
        "for Palavras, n  in PalFrequentesMP:\n",
        "  for PalavrasD, d in PalFrequentesDC:\n",
        "       if(Palavras == PalavrasD):\n",
        "              PalavrasSemelhantes += Palavras + '\\t' +' Quantidade Mémorias Póstumas: ' + str(n) +'\\t' + '  Quantidade Dom Casmurro: ' + str(d) + '\\n' \n",
        "             \n",
        "\n",
        "print(PalavrasSemelhantes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsAMAAAoB79k"
      },
      "source": [
        "# ***Representação Gráfica das vinte palavras mais frequentes nos arquivos***\n",
        "Aqui se encontra a representação gráfica das palavras 20 mais frequentes nos dois arquivos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0sQgeeiBlRJ"
      },
      "source": [
        "valor = []\n",
        "freq = []\n",
        "for Palavras, n  in PalFrequentesMP:\n",
        "          valor.append(Palavras)\n",
        "          freq.append(n)\n",
        "\n",
        "plt.title(\"Frequência de Palavras Memórias Póstumas\")\n",
        "plt.bar(valor, freq,width = 0.5, color='red')\n",
        "plt.gcf().set_size_inches(10, 15)\n",
        "plt.show()\n",
        "\n",
        "for Palavras, n  in PalFrequentesDC:\n",
        "          valor.append(Palavras)\n",
        "          freq.append(n)\n",
        "\n",
        "plt.title(\"Frequência de Palavras Dom Casmurro\")\n",
        "plt.bar(valor, freq,width = 0.5, color='blue')\n",
        "plt.gcf().set_size_inches(10, 15)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdi1lmWSKWXa"
      },
      "source": [
        "#***Referências***\n",
        "\n",
        "[1] Flávio Belizário da Silva Mota.   **Introdução ao Processamento de Linguagem Natural (PLN)**.              \n",
        "Disponível em\n",
        "https://github.com/flavio-mota/fundamentos-pln/blob/master/CIC260_Introdu%C3%A7%C3%A3o_ao_Processamento_de_Linguagem_Natural.ipynb.    Acesso em: Novembro de 2021.\n",
        "\n",
        "[2] PYTHON SOFTWARE FOUNDATION. **A Biblioteca Padrão do Python 2021** . Disponível em: <https://docs.python.org/pt-br/3/library/>. Acesso em: 15 de nov. de 2021."
      ]
    }
  ]
}